{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Training shots: 59\n",
      "Test shots: 20\n",
      "Validation shots: 20\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import dill\n",
    "from plot_utils import *\n",
    "from preprocess_datasets import load_features_outcomes, load_features_labels, make_training_sets\n",
    "from run_models import run_survival_model, run_rf_model, eval_model, save_model, load_model\n",
    "\n",
    "# Make training sets if they haven't been created yet\n",
    "\n",
    "device = 'cmod'\n",
    "dataset = 'random100'\n",
    "numeric_feats = ['ip','Wmhd','n_e','kappa','li']\n",
    "#numeric_feats=['aminor','n_e','ip','delta','li','Wmhd','kappa']\n",
    "\n",
    "\n",
    "# TODO: list disruptive vs non-disruptive shots in each dataset\n",
    "make_training_sets(device, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auton_survival.preprocessing import Preprocessor\n",
    "# Load and preprocess training, test, validation sets\n",
    "features_train, outcomes_train = load_features_outcomes(device, dataset+'_train', features=numeric_feats)\n",
    "features_test, outcomes_test = load_features_outcomes(device, dataset+'_test', features=numeric_feats)\n",
    "features_val, outcomes_val = load_features_outcomes(device, dataset+'_val', features=numeric_feats)\n",
    "\n",
    "# The features should match the above\n",
    "_, labels_train = load_features_labels(device, dataset+'_train', 0.15)\n",
    "_, labels_test = load_features_labels(device, dataset+'_test', 0.15)\n",
    "_, labels_val = load_features_labels(device, dataset+'_val', 0.15)\n",
    "\n",
    "# Fit the imputer and scaler to the training data and transform the training, test, and validation data\n",
    "preprocessor = Preprocessor(cat_feat_strat='ignore', num_feat_strat='mean')\n",
    "transformer=preprocessor.fit(features_train, cat_feats=[], num_feats=numeric_feats, one_hot=True, fill_value=-1)\n",
    "\n",
    "x_train = transformer.transform(features_train)\n",
    "x_test = transformer.transform(features_test)\n",
    "x_val = transformer.transform(features_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to models/cph_cmod_random100.pkl\n"
     ]
    }
   ],
   "source": [
    "# Train a cph model and save it\n",
    "cph_model = run_survival_model('cph', x_train, x_val, outcomes_train, outcomes_val)\n",
    "save_model(cph_model, transformer, 'cph', device, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to models/rf_cmod_random100.pkl\n"
     ]
    }
   ],
   "source": [
    "# Train a random forest model and save it\n",
    "rf_model = run_rf_model(x_train, x_val, labels_train, labels_val)\n",
    "save_model(rf_model, transformer, 'rf', device, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 29.68it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 30.36it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.23it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 18.23it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 30.88it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 30.92it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.46it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to models/dcph_cmod_random100.pkl\n"
     ]
    }
   ],
   "source": [
    "# Train a dcph model and save it\n",
    "dcph_model = run_survival_model('dcph', x_train, x_val, outcomes_train, outcomes_val)\n",
    "save_model(dcph_model, transformer, 'dcph', device, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Train a random survival forest model and save it\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m rsf_model \u001b[39m=\u001b[39m run_survival_model(\u001b[39m'\u001b[39;49m\u001b[39mrsf\u001b[39;49m\u001b[39m'\u001b[39;49m, x_train, x_val, outcomes_train, outcomes_val)\n\u001b[0;32m      3\u001b[0m save_model(rsf_model, transformer, \u001b[39m'\u001b[39m\u001b[39mrsf\u001b[39m\u001b[39m'\u001b[39m, device, dataset)\n",
      "File \u001b[1;32mc:\\Users\\zkeith\\Documents\\Risk-Aware Frameworks\\disruption-survival-analysis\\run_models.py:105\u001b[0m, in \u001b[0;36mrun_survival_model\u001b[1;34m(model_string, x_tr, x_val, y_tr, y_val)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    103\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid model string: \u001b[39m\u001b[39m{\u001b[39;00mmodel_string\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 105\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_tr, y_tr)\n\u001b[0;32m    107\u001b[0m \u001b[39m# Obtain survival probabilities for validation set and compute the Integrated Brier Score \u001b[39;00m\n\u001b[0;32m    108\u001b[0m predictions_val \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict_survival(x_val, times)\n",
      "File \u001b[1;32mc:\\Users\\zkeith\\Documents\\Risk-Aware Frameworks\\disruption-survival-analysis\\.venv\\lib\\site-packages\\auton_survival\\estimators.py:651\u001b[0m, in \u001b[0;36mSurvivalModel.fit\u001b[1;34m(self, features, outcomes, vsize, val_data, weights, weights_val, resample_size)\u001b[0m\n\u001b[0;32m    647\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model \u001b[39m=\u001b[39m _fit_cph(features, outcomes,\n\u001b[0;32m    648\u001b[0m                          val_data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_seed,\n\u001b[0;32m    649\u001b[0m                          \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhyperparams)\n\u001b[0;32m    650\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrsf\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 651\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model \u001b[39m=\u001b[39m _fit_rsf(features, outcomes,\n\u001b[0;32m    652\u001b[0m                          val_data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_seed,\n\u001b[0;32m    653\u001b[0m                          \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhyperparams)\n\u001b[0;32m    654\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdsm\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    655\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model \u001b[39m=\u001b[39m _fit_dsm(features, outcomes,\n\u001b[0;32m    656\u001b[0m                          val_data,\n\u001b[0;32m    657\u001b[0m                          \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_seed,\n\u001b[0;32m    658\u001b[0m                          \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhyperparams)\n",
      "File \u001b[1;32mc:\\Users\\zkeith\\Documents\\Risk-Aware Frameworks\\disruption-survival-analysis\\.venv\\lib\\site-packages\\auton_survival\\estimators.py:326\u001b[0m, in \u001b[0;36m_fit_rsf\u001b[1;34m(features, outcomes, val_data, random_seed, **hyperparams)\u001b[0m\n\u001b[0;32m    324\u001b[0m y \u001b[39m=\u001b[39m  Surv\u001b[39m.\u001b[39mfrom_dataframe(\u001b[39m'\u001b[39m\u001b[39mevent\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m, outcomes)\n\u001b[0;32m    325\u001b[0m \u001b[39m# Fit the RSF model\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m rsf\u001b[39m.\u001b[39;49mfit(features\u001b[39m.\u001b[39;49mvalues, y)\n\u001b[0;32m    327\u001b[0m \u001b[39mreturn\u001b[39;00m rsf\n",
      "File \u001b[1;32mc:\\Users\\zkeith\\Documents\\Risk-Aware Frameworks\\disruption-survival-analysis\\.venv\\lib\\site-packages\\sksurv\\ensemble\\forest.py:148\u001b[0m, in \u001b[0;36m_BaseSurvivalForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    138\u001b[0m trees \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    139\u001b[0m                               random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    140\u001b[0m          \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)]\n\u001b[0;32m    142\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m trees \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    149\u001b[0m                  prefer\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m'\u001b[39;49m)(\n\u001b[0;32m    150\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    151\u001b[0m         t, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap, X, (y_numeric, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevent_times_), sample_weight, i, \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    152\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    153\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap)\n\u001b[0;32m    154\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees))\n\u001b[0;32m    156\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\zkeith\\Documents\\Risk-Aware Frameworks\\disruption-survival-analysis\\.venv\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\zkeith\\Documents\\Risk-Aware Frameworks\\disruption-survival-analysis\\.venv\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 768\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[0;32m    770\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    605\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[0;32m    606\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 607\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    608\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train a random survival forest model and save it\n",
    "rsf_model = run_survival_model('rsf', x_train, x_val, outcomes_train, outcomes_val)\n",
    "save_model(rsf_model, transformer, 'rsf', device, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from models/cph_cmod_random100.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load a model\n",
    "cph_model = load_model('cph', device, dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
